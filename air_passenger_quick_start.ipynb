{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to RAMP platform and interaction with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAMP is a Kaggle-like platform. It is used to run data science challenge. Indeed, a challenge is organized around a specific problem for which the data and the evaluation are already defined. Participants will only have to focus on the development of the machine learning pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will present how the RAMP platform works. RAMP relies on a data science problem which is formulated in `problem.py`. It defines both data and evaluation. If you are interested, you can open this file. Otherwise, we will only used a couple of the function defined there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the training and testing datasets available for the challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = problem.get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = problem.get_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Succently, we can check the type of features in `X` and the target that we would like to predict `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target `y` corresponds to a number of passengers (modified using a `log` function). Associated with each target, we have an information in `X` related to the date (`DateOfDeparture`) and the airports of departure (`Departure`) and arrival (`Arrival`). Besides, we have the information regarding the mean (`WeeksToDeparture`) and standard deviation (`std_wtd`) of the time in weeks between the booking and the departure.\n",
    "\n",
    "So we try to answer to the following information: **With some flying information between airports, can we predict the (log) flow of passengers?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a basic scikit-learn model that could use some the data in `X` to answer this question. We will create a factory function `get_estimator()` to return the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def get_estimator():\n",
    "    cat_processor = OrdinalEncoder()\n",
    "    cat_columns = [\"Departure\", \"Arrival\"]\n",
    "\n",
    "    num_processor = \"passthrough\"\n",
    "    num_columns = [\"WeeksToDeparture\", \"std_wtd\"]\n",
    "\n",
    "    preprocessor = make_column_transformer(\n",
    "        (cat_processor, cat_columns),\n",
    "        (num_processor, num_columns),\n",
    "        remainder=\"drop\",  # drop the unused columns\n",
    "    )\n",
    "\n",
    "    return make_pipeline(preprocessor, RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.set_config(display=\"diagram\")\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = get_estimator()\n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we could train and test our model using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = get_estimator()\n",
    "cv = problem.get_cv(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(\n",
    "    model, X_train, y_train, cv=cv,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "for cv_idx, score in enumerate(rmse_scores):\n",
    "    print(f\"CV Fold #{cv_idx}: {score:.3f}\")\n",
    "print(\n",
    "    f\"RMSE = {rmse_scores.mean():.3f} \"\n",
    "    f\"+/- {rmse_scores.std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAMP was developed to avoid running the last cell. Instead, the idea is to store the content of cell where `get_estimator` is defined into a file. For this challenge, the name of the file is called `estimator.py`. You can check the content of `submissions/starting_kit` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make our first kit. Alongside of the three kits, create a folder `my_first_kit` in the folder `submissions`. The command below will create a `estimator.py` file into this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile submissions/my_first_kit/estimator.py\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def get_estimator():\n",
    "    cat_processor = OrdinalEncoder()\n",
    "    cat_columns = [\"Departure\", \"Arrival\"]\n",
    "\n",
    "    num_processor = \"passthrough\"\n",
    "    num_columns = [\"WeeksToDeparture\", \"std_wtd\"]\n",
    "\n",
    "    preprocessor = make_column_transformer(\n",
    "        (cat_processor, cat_columns),\n",
    "        (num_processor, num_columns),\n",
    "        remainder=\"drop\",  # drop the unused columns\n",
    "    )\n",
    "\n",
    "    return make_pipeline(preprocessor, RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `estimator.py` was created, we can use the `ramp-test` command to automatically execute the evaluation on our newly created estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ramp-test --submission my_first_kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command is the exact replica of what would happen on our server when you will submit your file `estimator.py` on https://ramp.studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make a demo on submitting this kit on the RAMP platform."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
